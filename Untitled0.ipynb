{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eragon3650/TechDocAnalysis/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s6PzCq_oGs9"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import datetime\n",
        "import string\n",
        "import math\n",
        "import os\n",
        "import functools\n",
        "import itertools\n",
        "import random\n",
        "from jiwer import wer\n",
        "\n",
        "from tqdm import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices()\n",
        "tf.autograph.set_verbosity(1)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "import keras_ocr\n",
        "import numpy as np\n",
        "from imutils import paths\n",
        "import imgaug\n",
        "import imgaug.augmenters as iaa\n",
        "import imutils\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pickle\n",
        "\n",
        "BS = 16\n",
        "\n",
        "data_dir = '.'\n",
        "alphabet = string.digits + string.ascii_letters + \"△;-/.:()%*='<>+&Δβ,≥±#~δλμ€α[]℃ \"\n",
        "\n",
        "recognizer = keras_ocr.recognition.Recognizer(\n",
        "    alphabet=alphabet,\n",
        "    weights=None,\n",
        ")\n",
        "recognizer_basepath = os.path.join(data_dir, 'drive/MyDrive/recognizer')\n",
        "\n",
        "\n",
        "class testModelCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, filepath):\n",
        "        super().__init__()\n",
        "        self.filepath = filepath\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        filepaths = self.filepath.copy()\n",
        "        random.shuffle(filepaths)\n",
        "        for i in range(len(filepaths) // 10):\n",
        "            filepath = filepaths[i]\n",
        "            text = valLabels[int(filepath.split(os.sep)[-1].split(\"/\")[-1].split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]) - 1]\n",
        "            image = filepath#keras_ocr.tools.read_and_fit(filepath, 180, 80)\n",
        "            #tf.cast(image, \"float32\")\n",
        "\n",
        "            batchPredict = [recognizer.recognize(image)]\n",
        "            predictions.extend(batchPredict)\n",
        "            targets.append(text)\n",
        "\n",
        "        print('=' * 100)\n",
        "        try:\n",
        "            score = wer(targets, predictions)\n",
        "            print(f'WER: {score}')\n",
        "            print('=' * 100)\n",
        "            for i in np.random.randint(0, len(predictions), 5):\n",
        "                print(f'Target: {targets[i]}')\n",
        "                print(f'Prediction: {predictions[i]}')\n",
        "                print('=' * 100)\n",
        "        except:\n",
        "            print([len(targets), len(predictions)])\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if (epoch % 5) == 0:\n",
        "            images = [\n",
        "                \"./Training/ch9_training_word_images_gt_new/word_3.png\",\n",
        "                \"./Val/ch9_validation_word_images_gt_new/word_4.png\",\n",
        "                \"./Val/ch9_validation_word_images_gt_new/word_8.png\",\n",
        "                \"./Val/ch9_validation_word_images_gt_new/word_456.png\",\n",
        "                \"./Training/ch9_training_word_images_gt_new/word_324.png\",\n",
        "                \"./Val/ch9_validation_word_images_gt_new/word_128.png\",\n",
        "            ]\n",
        "            for i in range(len(images)):\n",
        "                print(recognizer.recognize(images[i]))\n",
        "\n",
        "\n",
        "\n",
        "def get_image_generator(filepaths, augmenter, width, height, labels):\n",
        "    filepaths = filepaths.copy()\n",
        "    random.shuffle(filepaths)\n",
        "    for filepath in itertools.cycle(filepaths):\n",
        "        text = labels[int(filepath.split(os.sep)[-1].split(\"/\")[-1].split(\"/\")[-1].split(\"_\")[1].split(\".\")[0]) - 1]\n",
        "        image = keras_ocr.tools.read_and_fit(filepath, 240, 240)\n",
        "        tf.cast(image, \"float32\")\n",
        "        if augmenter is not None:\n",
        "            image = augmenter.augment_image(image)\n",
        "        if filepath == filepaths[-1]:\n",
        "            random.shuffle(filepaths)\n",
        "        yield image, text\n",
        "\n",
        "#for layer in recognizer.backbone.layers:\n",
        "#        layer.trainable = False\n",
        "classWeight = {}\n",
        "valLabels = []\n",
        "def setup():\n",
        "    trainLabels = []\n",
        "    with open(\"./Training/ch9_training_word_images_gt_new/gt.txt\") as f:\n",
        "            for line in f:\n",
        "                label = line.split(\"@\")[-1].strip()\n",
        "                label = \"\".join([c for c in label])# if c in alphabet])\n",
        "                trainLabels.append(\" \".join(label.split()))\n",
        "\n",
        "    with open(\"./Val/ch9_validation_word_images_gt_new/gt.txt\") as f:\n",
        "            for line in f:\n",
        "                label = line.split(\"@\")[-1].strip()\n",
        "                label = \"\".join([c for c in label])# if c in alphabet])\n",
        "                valLabels.append(\" \".join(label.split()))\n",
        "    imageTrain = sorted(list(paths.list_images(\"./Training/ch9_training_word_images_gt_new/\")))\n",
        "    imageVal = sorted(list(paths.list_images(\"./Val/ch9_validation_word_images_gt_new/\")))\n",
        "    for c in \"\".join(trainLabels + valLabels):\n",
        "                assert c in alphabet, f\"Found illegal character: {c}\"\n",
        "    labels = np.array(\n",
        "                [\n",
        "                    [alphabet.index(c) for c in sentence]\n",
        "                    + [len(alphabet)] * (recognizer.training_model.input_shape[1][1] - len(sentence))\n",
        "                    for sentence in trainLabels + valLabels\n",
        "                ]\n",
        "            )\n",
        "    le = MultiLabelBinarizer()\n",
        "    labels = le.fit_transform(labels)\n",
        "\n",
        "    classTotals = labels.sum(axis=0)\n",
        "\n",
        "    for i in range(0, len(classTotals)):\n",
        "        classWeight[i] = classTotals.max() / classTotals[i]\n",
        "\n",
        "    print(classWeight)\n",
        "\n",
        "    imgAug = iaa.Sequential([\n",
        "        iaa.Affine(\n",
        "          scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "          rotate=(-25, 25),\n",
        "          shear=(-8, 8)\n",
        "        ),\n",
        "        ])\n",
        "\n",
        "    (training_image_generator, training_steps),(validation_image_generator, validation_steps) = [\n",
        "            (get_image_generator(filepaths=filepaths,augmenter=augmenter,width=recognizer.model.input_shape[2],\n",
        "                                 height=recognizer.model.input_shape[1],labels=label), math.ceil(len(filepaths) / BS)) for filepaths, augmenter, label in [(imageTrain, imgAug, trainLabels),(imageVal, imgAug, valLabels)]]\n",
        "\n",
        "    train, val = [\n",
        "            tf.data.Dataset.from_generator(\n",
        "                functools.partial(\n",
        "                    recognizer.get_batch_generator,\n",
        "                    image_generator=image_generator,\n",
        "                    batch_size=BS,\n",
        "                ),\n",
        "                output_types=((tf.float32, tf.int32, tf.float32, tf.int32), tf.float32),\n",
        "                output_shapes=(\n",
        "                    (\n",
        "                        tf.TensorShape([None, 240, 240, 1]),\n",
        "                        tf.TensorShape([None, recognizer.training_model.input_shape[1][1]]),\n",
        "                        tf.TensorShape([None, 1]),\n",
        "                        tf.TensorShape([None, 1]),\n",
        "                    ),\n",
        "                    tf.TensorShape([None, 1]),\n",
        "                ),\n",
        "            )\n",
        "            for image_generator in [training_image_generator, validation_image_generator]\n",
        "        ]\n",
        "    return train, val\n",
        "\n",
        "train, val = setup()\n",
        "recognizer.training_model.summary()\n",
        "print(\"Starting...\")\n",
        "##if os.path.isfile('recognizer.h5'):\n",
        "##    recognizer.training_model.load_weights('recognizer.h5')\n",
        "while True:\n",
        "    recognizer.training_model.load_weights(f'{recognizer_basepath}.h5', skip_mismatch=True, by_name=True)\n",
        "    recognizer.compile()\n",
        "    #recognizer.training_model.save(\"recognizer.h5\")\n",
        "\n",
        "    recognizer.training_model.fit(\n",
        "        train,\n",
        "        epochs=250,\n",
        "        steps_per_epoch=2000 // BS,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", restore_best_weights=False, patience=10),\n",
        "            tf.keras.callbacks.CSVLogger(f'{recognizer_basepath}.csv', append=True),\n",
        "            tf.keras.callbacks.ModelCheckpoint(filepath=f'{recognizer_basepath}.h5', monitor=\"val_loss\"),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5),\n",
        "            testModelCallback(sorted(list(paths.list_images(\"./Val/ch9_validation_word_images_gt_new/\"))))\n",
        "        ],\n",
        "        validation_data=val,\n",
        "        validation_steps=800 // BS,\n",
        "        workers=0,\n",
        "        batch_size=BS,\n",
        "        #class_weight=classWeight,\n",
        "    )\n",
        "\n",
        "###################################################################################\n",
        "pipeline = keras_ocr.pipeline.Pipeline(recognizer=recognizer)\n",
        "\n",
        "images = [\n",
        "    \"./Training/ch9_training_word_images_gt_new/word_3.png\",\n",
        "    \"./Val/ch9_validation_word_images_gt_new/word_4.png\",\n",
        "    \"./Val/ch9_validation_word_images_gt_new/word_8.png\",\n",
        "    \"./Val/ch9_validation_word_images_gt_new/word_456.png\",\n",
        "    \"./Training/ch9_training_word_images_gt_new/word_324.png\",\n",
        "    \"./Val/ch9_validation_word_images_gt_new/word_128.png\"\n",
        "]\n",
        "\n",
        "prediction_groups = pipeline.recognize(images)\n",
        "print(prediction_groups)\n",
        "for i in range(len(images)):\n",
        "    #keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)\n",
        "    plt.imshow(images[i])\n",
        "    print(recognizer.recognize(images[i]))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G6WN4mvFGi85",
        "outputId": "63dde34d-3dba-4a0e-922e-b0696d481bed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keras Uncertainty will use standalone Keras backend"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " image (InputLayer)          [(None, 31, 200, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " permute (Permute)           (None, 31, 200, 1)           0         ['image[0][0]']               \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 31, 200, 1)           0         ['permute[0][0]']             \n",
            "                                                                                                  \n",
            " conv_1 (Conv2D)             (None, 31, 200, 64)          640       ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " conv_2 (Conv2D)             (None, 31, 200, 128)         73856     ['conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv_3 (Conv2D)             (None, 31, 200, 256)         295168    ['conv_2[0][0]']              \n",
            "                                                                                                  \n",
            " bn_3 (BatchNormalization)   (None, 31, 200, 256)         1024      ['conv_3[0][0]']              \n",
            "                                                                                                  \n",
            " maxpool_3 (MaxPooling2D)    (None, 31, 200, 256)         0         ['bn_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv_4 (Conv2D)             (None, 31, 200, 256)         590080    ['maxpool_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv_5 (Conv2D)             (None, 31, 200, 512)         1180160   ['conv_4[0][0]']              \n",
            "                                                                                                  \n",
            " bn_5 (BatchNormalization)   (None, 31, 200, 512)         2048      ['conv_5[0][0]']              \n",
            "                                                                                                  \n",
            " maxpool_5 (MaxPooling2D)    (None, 31, 200, 512)         0         ['bn_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv_6 (Conv2D)             (None, 31, 200, 512)         2359808   ['maxpool_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv_7 (Conv2D)             (None, 31, 200, 512)         2359808   ['conv_6[0][0]']              \n",
            "                                                                                                  \n",
            " bn_7 (BatchNormalization)   (None, 31, 200, 512)         2048      ['conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 200, 15872)           0         ['bn_7[0][0]']                \n",
            "                                                                                                  \n",
            " fc_9 (Dense)                (None, 200, 128)             2031744   ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 200, 256)             263168    ['fc_9[0][0]']                \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 200, 256)             1024      ['bidirectional[0][0]']       \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 200, 256)             394240    ['batch_normalization[0][0]'] \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 200, 256)             1024      ['bidirectional_1[0][0]']     \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 200, 256)             0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " fc_12 (Dense)               (None, 200, 95)              24415     ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " labels (InputLayer)         [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 200, 95)              0         ['fc_12[0][0]']               \n",
            "                                                                                                  \n",
            " input_length (InputLayer)   [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " label_length (InputLayer)   [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)           (None, 1)                    0         ['labels[0][0]',              \n",
            "                                                                     'lambda_1[0][0]',            \n",
            "                                                                     'input_length[0][0]',        \n",
            "                                                                     'label_length[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9580255 (36.55 MB)\n",
            "Trainable params: 9576671 (36.53 MB)\n",
            "Non-trainable params: 3584 (14.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Starting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a043c1755d2a>\u001b[0m in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     recognizer.training_model.fit(\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1796\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1797\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-a043c1755d2a>\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_ocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mbatchPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_ocr/recognition.py\u001b[0m in \u001b[0;36mrecognize\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    464\u001b[0m             [\n\u001b[1;32m    465\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank_label_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import datetime\n",
        "import string\n",
        "import math\n",
        "import os\n",
        "import functools\n",
        "import itertools\n",
        "import random\n",
        "from jiwer import wer\n",
        "import sklearn.model_selection\n",
        "from tqdm import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices()\n",
        "tf.autograph.set_verbosity(1)\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "import keras_ocr\n",
        "import numpy as np\n",
        "from imutils import paths\n",
        "import imgaug\n",
        "import imutils\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import keras_uncertainty\n",
        "from keras_uncertainty.utils import classifier_calibration_error, classifier_calibration_curve\n",
        "\n",
        "BS = 32\n",
        "\n",
        "data_dir = '.'\n",
        "alphabet = string.digits + string.ascii_letters + \"△;-/.:()%*='<>+&Δβ,≥±#~δλμ€α[]℃ \"\n",
        "#just download please hgfhfghdfghdfghfgdhfdghgfd\n",
        "recognizer = keras_ocr.recognition.Recognizer(\n",
        "    alphabet=alphabet,\n",
        "    weights=None,\n",
        ")\n",
        "recognizer_basepath = os.path.join(data_dir, 'drive/MyDrive/recognizer')\n",
        "\n",
        "class testModelCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, filepath):\n",
        "        super().__init__()\n",
        "        self.filepath = filepath\n",
        "\n",
        "    def on_epoch_begin(self, epoch: int, logs=None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        filepaths = self.filepath.copy()\n",
        "        random.shuffle(filepaths)\n",
        "        for i in range(10):\n",
        "            filepath = filepaths[i]\n",
        "            text = filepath.split(os.sep)[-1].split(\"_\")[1]\n",
        "            image = keras_ocr.tools.read_and_fit(filepath, 200, 31, cval=np.random.randint(low=0, high=255, size=3).astype(\"uint8\"))\n",
        "\n",
        "            batchPredict = [recognizer.recognize(image)]\n",
        "            predictions.extend(batchPredict)\n",
        "            targets.append(text)\n",
        "\n",
        "        print('=' * 100)\n",
        "        try:\n",
        "            score = wer(targets, predictions)\n",
        "            print(f'WER: {score}')\n",
        "            print('=' * 100)\n",
        "            for i in np.random.randint(0, len(predictions), 10):\n",
        "                print(f'Target: {targets[i]}')\n",
        "                print(f'Prediction: {predictions[i]}')\n",
        "                print('=' * 100)\n",
        "        except:\n",
        "            print([len(targets), len(predictions)])\n",
        "\n",
        "#    def on_epoch_begin(self, epoch, logs=None):\n",
        "#        if (epoch % 5) == 0:\n",
        "#            images = [\n",
        "#                keras_ocr.tools.read_and_fit(\"./ch9_training_word_images_gt_new/word_3.png\", 180, 180),\n",
        "#                keras_ocr.tools.read_and_fit(\"./Testing/word_4.png\", 180, 180),\n",
        "#                keras_ocr.tools.read_and_fit(\"./Testing/word_8.png\", 180, 180),\n",
        "#                keras_ocr.tools.read_and_fit(\"./Testing/word_456.png\", 180, 180),\n",
        "#                keras_ocr.tools.read_and_fit(\"./ch9_training_word_images_gt_new/word_324.png\", 180, 180),\n",
        "#                keras_ocr.tools.read_and_fit(\"./Testing/word_128.png\", 180, 180)\n",
        "#            ]\n",
        "#            for i in range(len(images)):\n",
        "#                print(recognizer.recognize(images[i]))\n",
        "\n",
        "\n",
        "\n",
        "def get_image_generator(filepaths, augmenter, width, height):\n",
        "    filepaths = filepaths.copy()\n",
        "    random.shuffle(filepaths)\n",
        "    for filepath in itertools.cycle(filepaths):\n",
        "        text = filepath.split(os.sep)[-1].split(\"_\")[0]\n",
        "        image = keras_ocr.tools.read_and_fit(filepath, 200, 31, cval=np.random.randint(low=0, high=255, size=3).astype(\"uint8\"))\n",
        "        if augmenter is not None:\n",
        "            image = augmenter.augment_image(image)\n",
        "        if filepath == filepaths[-1]:\n",
        "            random.shuffle(filepaths)\n",
        "        yield image, text\n",
        "\n",
        "def get_train_val_test_split(arr):\n",
        "    test, valtrain = sklearn.model_selection.train_test_split(arr, train_size=0.01, random_state=42)\n",
        "    val, train = sklearn.model_selection.train_test_split(valtrain, train_size=0.8, random_state=42)\n",
        "    return train, val, test\n",
        "\n",
        "#for layer in recognizer.backbone.layers:\n",
        "#        layer.trainable = False\n",
        "classWeight = {}\n",
        "valLabels = []\n",
        "def setup():\n",
        "    #trainLabels = []\n",
        "    #with open(\"ch9_training_word_images_gt_new/gt.txt\") as f:\n",
        "    #        for line in f:\n",
        "    #            label = line.split(\"@\")[-1].strip()\n",
        "    #            label = \"\".join([c for c in label])# if c in alphabet])\n",
        "    #            trainLabels.append(\" \".join(label.split()))\n",
        "#\n",
        "    #with open(\"ch9_validation_word_images_gt_new/gt.txt\") as f:\n",
        "    #        for line in f:\n",
        "    #            label = line.split(\"@\")[-1].strip()\n",
        "    #            label = \"\".join([c for c in label])# if c in alphabet])\n",
        "    #            valLabels.append(\" \".join(label.split()))\n",
        "    imageFiles = sorted(list(paths.list_images(\"./images\")))\n",
        "    #imageVal = sorted(list(paths.list_images(\"./validation/\")))\n",
        "    ##data_dir = Path(\"./captcha_images_v2/\")\n",
        "    ##labels = [filepath.split(os.path.sep)[-1].split(\".png\")[0] for filepath in sorted(list(map(str, list(data_dir.glob(\"*.png\")))))]\n",
        "    #for c in \"\".join(labels):\n",
        "    #            assert c in alphabet, f\"Found illegal character: {c}\"\n",
        "    #labels = np.array(\n",
        "    #            [\n",
        "    #                [alphabet.index(c) for c in sentence]\n",
        "    #                + [len(alphabet)] * (recognizer.training_model.input_shape[1][1] - len(sentence))\n",
        "    #                for sentence in labels\n",
        "    #            ]\n",
        "    #        )\n",
        "    #le = MultiLabelBinarizer()\n",
        "    #labelsCounting = le.fit_transform(labels)\n",
        "#\n",
        "    #classTotals = labelsCounting.sum(axis=0)\n",
        "#\n",
        "    #for i in range(0, len(classTotals)):\n",
        "    #    classWeight[i] = classTotals.max() / classTotals[i]\n",
        "#\n",
        "    #print(classWeight)\n",
        "#\n",
        "\n",
        "    training_filepaths, validation_filepaths, test_filepaths = get_train_val_test_split(imageFiles)\n",
        "\n",
        "    (training_image_generator, training_steps),(validation_image_generator, validation_steps),(test_image_generator, test_steps) = [\n",
        "            (get_image_generator(filepaths=filepaths,augmenter=None,width=recognizer.model.input_shape[2],\n",
        "                                 height=recognizer.model.input_shape[1]), math.ceil(len(filepaths) / BS)) for filepaths in [training_filepaths, validation_filepaths, test_filepaths]]\n",
        "\n",
        "    train, val, tester = [\n",
        "            tf.data.Dataset.from_generator(\n",
        "                functools.partial(\n",
        "                    recognizer.get_batch_generator,\n",
        "                    image_generator=image_generator,\n",
        "                    batch_size=BS,\n",
        "                ),\n",
        "                output_types=((tf.float32, tf.int32, tf.float32, tf.int32), tf.float32),\n",
        "                output_shapes=(\n",
        "                    (\n",
        "                        tf.TensorShape([None, 31, 200, 1]),\n",
        "                        tf.TensorShape([None, recognizer.training_model.input_shape[1][1]]),\n",
        "                        tf.TensorShape([None, 1]),\n",
        "                        tf.TensorShape([None, 1]),\n",
        "                    ),\n",
        "                    tf.TensorShape([None, 1]),\n",
        "                ),\n",
        "            )\n",
        "            for image_generator in [training_image_generator, validation_image_generator, test_image_generator]\n",
        "        ]\n",
        "    return train, val, tester\n",
        "\n",
        "train, val, test = setup()\n",
        "recognizer.training_model.summary()\n",
        "print(\"Starting...\")\n",
        "##if os.path.isfile('recognizer.h5'):\n",
        "#recognizer.training_model.load_weights(f'{recognizer_basepath}.h5')\n",
        "while True:\n",
        "  recognizer.training_model = tf.keras.models.load_model(f'{recognizer_basepath}.keras',compile=False,safe_mode=False)\n",
        "  #recognizer.training_model.load_weights(f'{recognizer_basepath}.h5', skip_mismatch=True, by_name=True)\n",
        "  recognizer.compile()\n",
        "  recognizer.training_model.save(f'{recognizer_basepath}.h5')\n",
        "\n",
        "  try:\n",
        "    recognizer.training_model.fit(\n",
        "        train,\n",
        "        epochs=250,\n",
        "        steps_per_epoch=8000 // BS,\n",
        "        callbacks=[\n",
        "            tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", restore_best_weights=False, patience=10),\n",
        "            tf.keras.callbacks.CSVLogger(f'{recognizer_basepath}.csv', append=True),\n",
        "            tf.keras.callbacks.ModelCheckpoint(filepath=f'{recognizer_basepath}.keras', monitor=\"val_loss\"),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=5),\n",
        "            testModelCallback(sorted(list(paths.list_images(\"./images\"))))\n",
        "        ],\n",
        "        validation_data=val,\n",
        "        validation_steps=2000 // BS,\n",
        "        workers=0,\n",
        "        batch_size=BS,\n",
        "        #class_weight=classWeight,\n",
        "    )\n",
        "  except Exception as error:\n",
        "    print(f\"{error} continuing...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07BZHVIRoWYt"
      },
      "outputs": [],
      "source": [
        "!mkdir Training\n",
        "!unzip Training.zip -d Training\n",
        "!mkdir Val\n",
        "!unzip Validation.zip -d Val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z0m3i3hxt3tE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8ef9c8-b16c-459a-b240-558cee0b4885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Eragon3650/keras-ocr.git\n",
            "  Cloning https://github.com/Eragon3650/keras-ocr.git to /tmp/pip-req-build-eukmk0r4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Eragon3650/keras-ocr.git /tmp/pip-req-build-eukmk0r4\n",
            "  Resolved https://github.com/Eragon3650/keras-ocr.git to commit b5c1da78cc39faa42a0216316efd06cbf07e7de7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/mvaldenegro/keras-uncertainty.git\n",
            "  Cloning https://github.com/mvaldenegro/keras-uncertainty.git to /tmp/pip-req-build-t_xz8t7k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mvaldenegro/keras-uncertainty.git /tmp/pip-req-build-t_xz8t7k\n",
            "  Resolved https://github.com/mvaldenegro/keras-uncertainty.git to commit 42f50a36c70003b16b7f343002766708ad2a289a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
            "Collecting stn\n",
            "  Downloading stn-1.0.1-py3-none-any.whl (3.9 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras-ocr==0.0.0) (0.6.2)\n",
            "Collecting efficientnet==1.0.0 (from keras-ocr==0.0.0)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting essential_generators (from keras-ocr==0.0.0)\n",
            "  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras-ocr==0.0.0) (4.48.1)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras-ocr==0.0.0) (0.4.0)\n",
            "Collecting pyclipper (from keras-ocr==0.0.0)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras-ocr==0.0.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras-ocr==0.0.0) (4.66.1)\n",
            "Collecting validators (from keras-ocr==0.0.0)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras-ocr==0.0.0)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras-ocr==0.0.0) (0.19.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stn) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Uncertainty==0.0.1) (2.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from Keras-Uncertainty==0.0.1) (1.11.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr==0.0.0) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr==0.0.0) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr==0.0.0) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras-ocr==0.0.0) (2.31.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras-ocr==0.0.0) (3.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.0.0) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.0.0) (2024.1.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras-ocr==0.0.0) (1.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr==0.0.0) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr==0.0.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras-ocr==0.0.0) (3.1.1)\n",
            "Building wheels for collected packages: keras-ocr, Keras-Uncertainty\n",
            "  Building wheel for keras-ocr (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-ocr: filename=keras_ocr-0.0.0-py3-none-any.whl size=42102 sha256=e87b9e31f9fcf06f26fcc571823279c1f50adbc1f73c26d63017b60337b73a3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8qozawz0/wheels/b6/a1/30/f9ef8d89a03ef2c38c26f333bb10f3024c1a47cec3f27575c0\n",
            "  Building wheel for Keras-Uncertainty (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Keras-Uncertainty: filename=Keras_Uncertainty-0.0.1-py3-none-any.whl size=37767 sha256=c2b843be48b8433c4d96b2417cee4f90dd27d4259b5a99c963fa82727a8e162c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8qozawz0/wheels/ca/4e/2f/97609d4065ffb545a5e867c8b31430161987f4702ecf61a96d\n",
            "Successfully built keras-ocr Keras-Uncertainty\n",
            "Installing collected packages: pyclipper, essential_generators, validators, stn, rapidfuzz, pyarrow, dill, multiprocess, Keras-Uncertainty, keras-applications, jiwer, efficientnet, keras-ocr, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Keras-Uncertainty-0.0.1 datasets-2.17.0 dill-0.3.8 efficientnet-1.0.0 essential_generators-1.0 jiwer-3.0.3 keras-applications-1.0.8 keras-ocr-0.0.0 multiprocess-0.70.16 pyarrow-15.0.0 pyclipper-1.3.0.post5 rapidfuzz-3.6.1 stn-1.0.1 validators-0.22.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade jiwer git+https://github.com/Eragon3650/keras-ocr.git stn datasets git+https://github.com/mvaldenegro/keras-uncertainty.git\n",
        "!tar -xzf drive/MyDrive/syntextDownsize.tar.gz"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rsffa_6t1NrujyGD4yek4gTT94nxXPuS",
      "authorship_tag": "ABX9TyMbQlQFJI1Pz5rRQnR8SHwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}